---
title: 'A "Tiered Assimilation, Match, and Model" (**TAMM**) approach for nationwide water system boundary estimation'
output: 
  html_document:
    highlight: zenburn
    code_folding: hide
    toc: true
    toc_float: true
    toc_depth: 4
    # number_sections: true
---

```{=html}
<style type="text/css">
  /* Whole document: */
  body{
    font-family: Helvetica;
    font-size: 13pt;
  }
  /* Headers */
  h1{
    font-size: 36pt;
  }
  h2{
    font-size: 30pt;
  }
  h3{
    font-size: 24pt;
  }
  h4{
    font-size: 18pt;
  }
  h5{
    font-size: 14pt;
  }
}

</style>
```

```{r setup, include=FALSE}
knitr::opts_chunk$set(warning = FALSE, message = FALSE, out.width = "100%")

# function to output customized HTML datatable with buttons
dt_make <- function(x){
  x %>% 
    DT::datatable(
    rownames = FALSE, 
    extensions = 'Buttons', 
    options = list(
      dom = 'Bfrtip', 
      buttons = c('copy', 'csv', 'excel')
    )
  )
}

# converts a float to a string with appropriate commas
format_bign <- function(x) formatC(x, big.mark = ",", format = "d")
```

*Jess Goddard, Rich Pauloo, Ryan Shepherd, Noor Brody*

*Last updated `r Sys.time()`*

<br>

# Introduction

In this report, we present a nationwide water service spatial boundary layer for community water systems and explain the tiered approach taken towards this end. This report builds on a previous technical memorandum ([`eda_february.html`](#)) that should be read as prerequisite material to understand the broader context, background, and exploratory data analysis (EDA) that informs the approach taken herein.

The resulting national water service boundary layer is the product of a "Tiered Assimilation, Match, and Model" (henceforth, **TAMM**) approach. The TAMM is composed of three hierarchical tiers, arranged by data and model fidelity.

1.  Whenever present, we use *explicit water service boundaries* (labeled data). These are spatial polygon data, typically provided at the state-level.\
2.  In the absence of explicit water service boundary data, we use a matching algorithm to match PWSIDs by spatial intersection and name to [TIGER place polygons](https://www.census.gov/geographies/mapping-files/time-series/geo/tiger-line-file.html){target="_blank"}. We validate this heuristic approach on explicit water service boundaries[^1], and find favorable results consistent with independent validation of the approach by [Patterson et al. (2019)](https://nicholasinstitute.duke.edu/publications/sensitivity-analysis-using-municipal-boundaries-proxy-service-area-boundaries-when){target="_blank"}.\
3.  Finally, in the absence of an explicit water service boundary (Tier 1) or a TIGER place polygon match (Tier 2), a statistical model trained on explicit water service boundary data (Tier 1) is used to estimate a reasonable radius at provided PWSID centroids, notwithstanding centroid accuracy issues that remain intractable at this point in time (centroid accuracy is discussed in the [Limitations](#limitations) section with recommendations for future work).

[^1]: In a previous report (`eda_february.html`,"*Section* *6 TIGER proxy polygon appropriateness*"), we show that matching PWSID to TIGER places is highly accurate: matched TIGER place polygons intersected explicit water service boundary polygons 93.16% of the time. In this report, we further quantify this boolean (TRUE/FALSE) spatial intersection in terms of "percent overlap".

Below is a conceptual diagram of the three tiers in the TAMM approach. Tier 1 boundary data always supersedes Tier 2 proxy boundaries, which in turn always supersedes Tier 3 modeled boundaries. Thus, the resulting the resulting water service boundary layer described in this report is combination of all three tiers, and depends on data availability for the water system, and whether or not it matches to a TIGER place.

```{r conceptual model, echo = FALSE}
knitr::include_graphics(here::here("src/analysis/sandbox/model_explore/etc/sl-march-2020.png"))
```

In the sections that follow, we summarize our approach for each of the three tiers. As we move from Tier 1 to Tier 3, uncertainty increases, hence, we describe each Tier with increasing detail and provide measures of validation and uncertainty for Tier 2 and 3 estimates.

Finally, we encourage the reader to consider the TAMM water service boundary layer not as a final product, but rather, one that may be improved with the assimilation of additional Tier 1 data, improvements to the Tier 2 matching algorithm, and refinement of the Tier 3 model. Ultimately, this entire workflow may be superseded by nationwide Tier 1 data, which would reduce the problem we address in the scope of work to one of simple Tier 1 data assimilation and cleaning.

<br>

# Report outline

The following outline reflects a summary of key findings, followed by a description of each Tier in the TAMM approach. Notably, the TAMM may be refined and re-run as new data sources are ingested or improvements are made to matching and modeling algorithms.

*Key Results*

-   A nationwide water service boundary layer is provided for X community water systems covering Y population\
-   Coverage rates per Tier:
    -   Tier 1: X% (count in millions)\
    -   Tier 2: Y% (count in millions)\
    -   Tier 3: Z% (count in millions)\
-   Unequal Tier distribution across states suggests that the confidence in water service boundary location and extent varies by state and system.\
-   Uncertainty metrics for Tier 2 and 3 estimates suggest that the TAMM approach provides a reasonable preliminary water service boundary layer.

*Tier 1: Assimilated explicit boundaries*

-   Data discovered for X states.\
-   We consider these data as "high quality" and use them to model Tier 3 boundaries.

*Tier 2: Matched TIGER proxy boundaries*

-   X% of water systems match a TIGER place by spatial intersection or name match.\
-   Spatial and name matching is constrained within the reported state to prevent out-of-state mismatches.\
-   For multiple spatial or name matches, minimum distance between the reported centroid of the PWSID and the TIGER place centroid is used to break ties.

*Tier 3: Modeled boundaries*

-   Circular water service boundary estimates are calculated for all water systems; median, 5% and 95% confidence intervals are provided to reflect medium, low, and high water service boundary estimates.
-   The the multiple linear regression fit has an impressive $R^2 = 0.67$ and is mostly explained by service connection count, which intuitively makes sense: there is roughly linear scaling between service connection count and the spatial extent of a water service area.

<br>

# Key Results

The key result of this study is a nationwide water service boundary layer. Here we show the proportion of population served by each TAMM Tier at nationwide and statewide scales.

<br>

## Tier coverage - nationwide 

```{r load}
library(tidyverse)
library(tidymodels)
library(sf)
library(fs)
library(knitr)
library(rcartocolor)
library(geofacet)

# load environmental variable for staging path 
staging_path <- Sys.getenv("WSB_STAGING_PATH")

# labeled data
wsb_labeled_clean <- path(staging_path, "wsb_labeled_clean.geojson") %>% 
  st_read(quiet = TRUE)

# service connection count cutoff for community water systems
n_max <- 15

# read the clean matched output and perform minor transforms for plots
d <- read_csv(path(staging_path, "matched_output_clean.csv")) %>%
  mutate(
    # transform radius from m to km
    radius = radius/1000,
    # indicate the tier of the wsb
    tier = case_when(
      has_labeled_bound == TRUE ~ "Tier 1",
      has_labeled_bound == FALSE & !is.na(tiger_match_geoid) ~ "Tier 2",
      has_labeled_bound == FALSE & is.na(tiger_match_geoid)  ~ "Tier 3"
    )
  ) %>% 
  # filter to CWS and assume each connection must serve at least 1 person
  # this drop 267 rows (0.5% of data)
  filter(service_connections_count >= n_max,
         population_served_count   >= n_max) %>% 
  # remove another 472 rows (1% of data) that are not in the contiguous 
  # USA, mostly from Puerto Rico
  filter(state_code %in% state.abb)

# popultion served by all water systems
pop_total <- sum(d$population_served_count)
```

In total, the TAMM data layer represents tap water delivery to `r round(pop_total/1e6, 2)` million people served by the `r format_bign(nrow(d))` water systems. 

```{r tamm nationwide coverage count and prop}
# calculate count and proportion of people served by each tier
pop <- d %>% 
  group_by(tier) %>% 
  summarize(
    count = format_bign(sum(population_served_count)),
    prop  = round((sum(population_served_count)/pop_total)*100, 2)
  )
```

About `r str_sub(pop$count, 1, 3)[1]` million people are covered by Tier 1 spatial data, impressive given that only `r wsb_labeled_clean$state %>% unique() %>% length()` states that provided explicit boundary data. However, this relatively high coverage rate is unsurprising because these states (`r wsb_labeled_clean$state %>% unique() %>% sort() %>% paste(collapse = ", ")`) include notable centers of high-population like CA, TX, and PA. 

Together, around `r str_sub(sum((as.numeric(str_remove_all(pop$count[1:2], ",")))), 1, 3)` million people (`r sum(pop$prop[1:2])`% of the population) are covered by either a Tier 1 or a Tier 2 spatial boundary. The remaining approximately `r str_split(pop$count[3], ",", simplify = TRUE)[1]` million people (`r pop$prop[3]`%) are covered by a Tier 3 boundary. These results indicate high confidence in the spatial accuracy of the resulting TAMM water boundary layer for community water systems. 

```{r tamm nationwide kable}
pop %>% 
  kable(col.names = c("Tier", "Population count", "Population proportion (%)")) %>% 
  kableExtra::kable_styling(full_width = FALSE)
```

<br> 

## Tier coverage - statewide 

Next, we show the proportion of population covered per TAMM Tier on a state-by-state basis. Notably:

- When Tier 1 data is present (orange bars below), it tends to cover a majority of the population.  
- Tier 2 (blue bars below) covers more population than Tier 3 across all states.  
- Tier 3 coverage (grey bars below) is not uniform across states. This implies that the Tier 2 matching algorithm may perform better in some states, and may depend on factors that vary across states, like centroid accuracy and water system type (e.g., municipal). 

```{r geofacet tamm tier distribution per state}
# dataframe for barplot geofacet: population prop served by each tier
dg <- d %>% 
  group_by(state_code) %>%
  # population per state
  mutate(state_pop = sum(population_served_count)) %>%
  ungroup() %>% 
  group_by(state_code, tier) %>% 
  # calculate count/proportion of population served per state and tier
  summarise(
    count = sum(population_served_count),
    prop  = count/state_pop
  ) %>% 
  ungroup() %>% 
  distinct() %>% 
  # add missing NA values per state code and tier group
  complete(state_code, tier) %>% 
  mutate(tier = factor(tier, levels = paste("Tier", 3:1)))

# sanity check the grouped summary above: this should return all 1
# group_by(dg, state_code) %>% 
#   summarise(s = sum(prop, na.rm = TRUE)) %>% 
#   pull(s) 

# geofacet of TAMM tier coverage per state in terms of population proportion
dg %>% 
  ggplot(aes(tier, prop, fill = tier)) + 
  geom_col() + 
  coord_flip() +
  scale_fill_carto_d(direction = -1) +
  scale_y_continuous(breaks = c(0, 1, 0.5), 
                     labels = c(0, 1, 0.5)) +
  geofacet::facet_geo(~state_code) +
  labs(x = "", y = "Population proportion") +
  guides(fill = "none") +
  theme_minimal(base_size = 6) +
  theme(panel.grid.minor.x = element_blank())
```

A data table of the the above plot is provided below.

```{r datatable tamm tier distribution per state}
dg %>% 
  mutate(
    count = ifelse(is.na(count), 0, count),
    count = format_bign(count),
    prop  = ifelse(is.na(prop), 0, prop),
    prop  = round(prop, 3)
  ) %>% 
  dt_make()
```

<br> 

## National boundary layer

The national water service boundary layer is too large to plot in this interactive report. We show a static map below to illustrate the coverage provided by the Tiers 1-3 in the proportions described above.  

```{r tamm nationwide wsb}

```

Next, we review the construction of each tier in increasing detail. 

<br>

# Tier 1: *Assimilated* boundaries

Tier 1 boundaries are the most straightforward to understand, but their "missingness" at 

```{r}
# wsb_labeled_clean 
```

Tier 1 explicit spatial boundary data is obtained from the following web addresses.

URL table. Standard downloaders/transformers. Should expand in future work.

Uncertainty out of our hands - depends on the state.

<br>

# Tier 2: *Matched* boundaries

Ryan's section with conceptual model.

<br>

## Uncertainty

We estimate the range of uncertainty in the Tier 2 approach with a *Modified [Jacard Similarity](https://en.wikipedia.org/wiki/Jaccard_index){target="_blank"}*, defined as the proportion of area overlap between the TIGER match and the underlying water service boundary, which we can calculate by comparing Tier 2 matches to all Tier 2 data:

$$
J = \frac{A_T \cap A_E }{A_E}
$$ where $A_T \cap A_E$ is the intersection of the TIGER Place area ($A_T$) and the explicit Tier 1 water service boundary area ($A_E$). Thus, the quantity $J$ is a closed interval between 0 and 1, inclusive: $\{J \space \space | \space \space 0 \le J \le 1\}$. Importantly, $A_T$ can fall outside of $A_E$ -- $J$ measures the proportion of coverage that $A_T$ provides over $A_E$.

```{r modified jacard similarity on tiger place match and labeled wsb}

```

Interpret plot above.

See 93% overlap in previous EDA as starting point.

<br>

# Tier 3: *Modeled* boundaries

We experimented with 3 different models: random forest, xgboost, and multiple linear regression. Model specification hinges on the correlation between the radius of Tier 1 convex hulls[^2] (the response variable), and predictors that explain this response, such as service connection count, population served, ownership type and so on. Moreover, different statistical and machine learning models have different assumptions and performance, which are discussed in the sections that follow.

[^2]: Labeled radii are calculated from the convex hull area of Tier 1 systems instead of simple water system area because they better represent calculated Tier 3 circular buffers.

Ultimately, we selected the multiple linear regression model because it is computationally efficient, easily interpretable, provides confidence intervals to characterize uncertainty in the modeled boundary which may be useful depending on the application of the model results, and finally because it avoids overfitting (the linear model actually results in the lowest error of the models tested).

<br>

## EDA

In this section of the report, we expand on important data pre-processing steps, feature selection/engineering, and developed models.

### Right skewed response

The response variable (radius) is right-skewed. The median radius is `r round(median(d$radius, na.rm = TRUE), 2)` km, and the maximum radius is `r round(max(d$radius, na.rm = TRUE), 2)` km. Linear models assumes constant variance and normality, thus we log-transform the response to [stabilize its variance](https://en.wikipedia.org/wiki/Variance-stabilizing_transformation){target="_blank"}, enable regression and inference approaches, prevent high-leverage radii from exerting too much influence on the model fit, and disallow predicted negative radii.

```{r}
d %>% 
  ggplot(aes(radius)) + 
  geom_histogram(bins = 100, col= "white") +
  labs(x = "Radius (km)")
```

The main drawback of log-transformation is that model coefficient units (e.g., slope of the regression fit) and measures of performance (e.g., RMSE) become difficult to interpret, however there are [methods](https://data.library.virginia.edu/interpreting-log-transformations-in-a-linear-model/){target="_blank"} to handle this interpretation[^3]. The benefits of log-transformation outweigh the drawbacks, thus we log-transform the response variable.

[^3]: **When only the dependent/response variable is log-transformed**: exponentiate the coefficient, subtract one from this number, and multiply by 100. This gives the percent increase (or decrease) in the response for every one-unit increase in the independent variable. Example: the coefficient is 0.198. (exp(0.198) -- 1) \* 100 = 21.9. For every one-unit increase in the independent variable, our dependent variable increases by about 22%.

Moreover, to avoid over-fitting a model on a training set that over-represents the more common low-radius observations, we perform a *stratified random sample* on the response variable. This samples equal proportions of training observations from each of quartiles of the radius distribution, delineated by red dashed lines in the figure below.

```{r}
d %>% 
  # calculate quantiles to show stratified random sampling
  mutate(
    p25 = quantile(radius, 0.25, na.rm = TRUE),
    p50 = quantile(radius, 0.50, na.rm = TRUE),
    p75 = quantile(radius, 0.75, na.rm = TRUE)
  ) %>% 
  ggplot(aes(radius)) + 
  geom_histogram(bins = 100, col= "white") + 
  geom_vline(aes(xintercept = p25), linetype = "dashed", color = "red") +
  geom_vline(aes(xintercept = p50), linetype = "dashed", color = "red") +
  geom_vline(aes(xintercept = p75), linetype = "dashed", color = "red") +
  scale_x_log10() +
  labs(x = "Radius (km)")
```

### Correlated predictors

Population served and service connections are highly correlated ($r$ $=$ `r round(tidy(cor.test(d$population_served_count, d$service_connections_count))$estimate, 2)`) and exhibit log-normality. Thus, like the response variable, they are log-transformed, which further impacts the interpretation of the regression fit[^4].

[^4]: **Both dependent/response variable and independent/predictor variable(s) are log-transformed:** Interpret the coefficient as the percent increase in the dependent variable for every 1% increase in the independent variable. Example: the coefficient is 0.198. For every 1% increase in the independent variable, our dependent variable increases by about 0.20%. For x percent increase, calculate 1.x to the power of the coefficient, subtract 1, and multiply by 100. Example: For every 20% increase in the independent variable, our dependent variable increases by about (1.20 ^0.198^ -- 1) \* 100 = 3.7 percent.

```{r}
d %>% 
  ggplot(aes(population_served_count, service_connections_count)) + 
  geom_point(aes(color = is_wholesaler_ind), alpha = 0.2) +
  rcartocolor::scale_color_carto_d() +
  scale_x_log10() +
  scale_y_log10() +
  labs(x = "Poulation served", 
       y = "Service connections",
       color = "Is Wholesaler")
```

### Interaction effects

#### Owner type code {#owner-type-code}

Regression slopes differ for the population served based on **owner type code**. This suggests an interaction term between population served and the owner type. Most systems are owned by local governments (L) or private (P) entities. Moreover, Native American (N) systems ($n$ $=$ 2) are poorly represented -- this should be addressed in future work. For modeling purposes and until more data are collected, we re-classify Native American observations into the Public/Private category (M).

```{r}
d %>% 
  ggplot(aes(population_served_count, radius)) + 
  geom_point(alpha = 0.2) + 
  geom_smooth(method = "lm", se = FALSE) +
  facet_wrap(~owner_type_code) + 
  rcartocolor::scale_color_carto_d() +
  scale_x_log10() +
  scale_y_log10() +
  labs(x = "Poulation served", 
       y = "Radius")
```

#### Wholesaler

As before with owner type code, wholesaler status interacts with population served, thus we include an interaction effect for it in the linear model.

```{r}
d %>% 
  ggplot(aes(population_served_count, radius)) + 
  geom_point(alpha = 0.2) + 
  geom_smooth(method = "lm", se = FALSE) +
  facet_wrap(~is_wholesaler_ind) + 
  scale_x_log10() +
  scale_y_log10() +
  labs(x = "Poulation served", 
       y = "Radius (km)")
```

#### Service area type code

Only `r round((nrow(filter(d, is.na(service_area_type_code)))/nrow(d))*100,2)`% of observations have a missing service area type feature. At first glance, there are `r length((table(d$service_area_type_code)))` unique service area type codes, with many systems that show a combination of more than one type. However, upon closer inspection, service area type code combinations are often permutations of one another (e.g., "['RA', 'SC']" and "['SC', 'RA']"). Thus, we clean them to find truly unique service area type code combinations, select the top 5 as features for the model, lump everything else into an "Other" category, and train on this feature. We include an interaction effect for service area type code.

```{r}
# clean service area type code column
d <- d %>% 
  mutate(
    # split type codes in the "python list" into chr vectors
    satc = strsplit(service_area_type_code, ", "),
    # map over the list to remove brackets ([]) and quotes (')
    satc = map(satc, ~str_remove_all(.x, "\\[|\\]|'")),
    # sort the resulting chr vector
    satc = map(satc, ~sort(.x)), 
    # collapse the sorted chr vector
    satc = map_chr(satc, ~paste(.x, collapse = ""))
  ) 
```

After cleaning, there are `r length((table(d$satc)))` truly unique service area type code combinations, and most are "RA" or "MH". Regression slopes appear similar, but with difference y intercepts, which suggest that some service area types are larger for an equal population. We may consider cleaning this further in a future iteration if domain knowledge indicates predictive power, although preliminary visual inspection (below) suggests little explanatory power. 

```{r}
# plot population v radius and facet by top 5 service area type code
d %>% 
  mutate(
    satc = fct_lump_n(satc, 5), 
    satc = as.character(satc), 
    satc = ifelse(is.na(satc), "Other", satc)
  ) %>%
  ggplot(aes(population_served_count, radius)) + 
  geom_point(alpha = 0.2) +
  geom_smooth(method = "lm", se = FALSE) + 
  facet_wrap(~satc) +
  scale_x_log10() +
  scale_y_log10() +
  labs(x = "Population served count", y = "Radius (km)")
```

## Models

We fit random forest, xgboost, and multiple linear regression models to a training set of 80% of the data selected by [stratified random sampling to avoid overfitting to low-radius observations](#right-skewed-response). We then evaluate model performance on the 20% holdout test set, discuss model uncertainty and limitations, interpret model results, and use the model to generate Tier 3 predictions on unlabeled data not covered by Tier 1 or 2 boundaries. 

### Random Forest

We first fit a random forest model to the data because the algorithm has less strict assumptions, it can handle correlated predictors, and because the variable importance output can quickly indicate which variables explain the most variance in the dataset and hence, what to focus on with more interpretable linear models. 

### Model evaluation

#### Random Forest ()

#### Tuned xgboost ()

#### Linear model (connections)

We use these first to specify linear models, which have more assumptions and constraints in order to be fit but which offer measures of standard error and greater interpretability.


#### Linear model (connections, owner type)

#### Linear model (connections, owner type, service area type)

#### Linear model (connections, owner type, service area type, wholesaler)

#### Linear model (connections, owner type, service area type, wholesaler)

#### Linear model (person-connections, owner type, service area type, wholesaler)

## Uncertainty

Linear model CIs.

### Limitations {#limitations}

No model is without limitations. In this section, we highlight key limitations and identify potential future pathways to improve the model fit through additional data collection and/or cleaning.

#### Missing Primacy Types

We lack labeled data and hence radii for tribal primacy types (and territories, although this analysis excludes them), and can't improve the model based on this information until it is collected. Thus, Tier 3 tribal community water system boundaries are fit by models trained on state primacy types, which may introduce error in modeled boundaries. This issue is related to missing "owner type codes" for "native" (N) water systems, described [above](#owner-type-code).

```{r}
d %>% 
  group_by(primacy_type) %>% 
  summarise(proportion_present = sum(!is.na(radius))/n(),
            proportion_present = round(proportion_present, 2)) %>% 
  dt_make()
```

#### Centroid Accuracy and the "Pancake Problem"

The "pancake problem" impacts PWSIDs that lack an explicit boundary (or TIGRIS match) and that suffer from low centroid accuracy (e.g., country centroid accuracy). Estimated radii for these systems result in circular buffers that overlap, like a stack of pancakes. Efforts may be made to "spatially dis-aggregate" or "spread out" the pancakes to more reasonable locations. One approach is to relocate low accuracy centroids to the centroids of [cities and towns](https://hifld-geoplatform.opendata.arcgis.com/datasets/cities-and-towns-ntad/explore?location=44.247405%2C-113.640330%2C3.84&showTable=true){target="_blank"} that fall within the county/state (depending on the centroid accuracy). Candidate cities for pancakes may be identified via a name match.

Upstream centroid accuracy issues are beyond the scope of this study, and may be addressed in coordination with federal agencies that produce FRS and ECHO databases.

# Contributions

# Recommendations

-   Explicit boundary data supersedes TIGER proxy matches and estimated water system boundaries. Moreover, it improves the statistical model prediction by providing more training data for similar systems with missing boundary data or a matching TIGER place. In theory, explicit boundary data for each state across the USA would .
-   Gather labeled boundaries for tribal primacy type (and territories if coverage is to be extended to these regions).
-   There are `r length((table(d$service_area_type_code)))` unique service area type code combinations, and many are combinations of different types.

<br><br>
